# -*- coding: utf-8 -*-
"""xgboostv3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e40h7Xpi1kRUehJpJqVLi9B-FxfNcs63
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_auc_score, precision_score, recall_score, f1_score
)
from sklearn.preprocessing import label_binarize
from sklearn.utils.class_weight import compute_sample_weight
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import uniform, randint
from pathlib import Path


df = pd.read_csv('/content/drive/My Drive/normalizedXGBoost.csv')

df.head()

y = df['target']
X = df.drop('target', axis=1)

print("="*60)
print("ANALYSE DES CLASSES")
print("="*60)
print(f"Classes uniques: {sorted(y.unique())}")
print(f"Distribution des classes:")
print(y.value_counts().sort_index())
print(f"\nProportions:")
print(y.value_counts(normalize=True).sort_index())

# Mapper les classes pour XGBoost (doit être 0, 1, 2)
# -1 (Down) -> 0, 0 (Hold) -> 1, 1 (Up) -> 2
class_mapping = {-1: 0, 0: 1, 1: 2}
reverse_mapping = {0: 'Down', 1: 'Hold', 2: 'Up'}
y_encoded = y.map(class_mapping)

# Split temporel: 70% train, 15% validation, 15% test
train_idx = int(len(X) * 0.70)
val_idx = int(len(X) * 0.85)

X_train = X[:train_idx].values
y_train = y_encoded[:train_idx].values
X_val = X[train_idx:val_idx].values
y_val = y_encoded[train_idx:val_idx].values
X_test = X[val_idx:].values
y_test = y_encoded[val_idx:].values

print(f"\n{'='*60}")
print("SPLITS TEMPORELS")
print("="*60)
print(f"Train: {X_train.shape} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Validation: {X_val.shape} ({len(X_val)/len(X)*100:.1f}%)")
print(f"Test: {X_test.shape} ({len(X_test)/len(X)*100:.1f}%)")
print(f"\nDistribution classes train:")
unique, counts = np.unique(y_train, return_counts=True)
for cls, count in zip(unique, counts):
    print(f"  Classe {cls} ({reverse_mapping[cls]}): {count} ({count/len(y_train)*100:.1f}%)")

print("CALCUL OF SAMPLE WEIGHTS")

class_counts = pd.Series(y_train).value_counts().sort_index()
total = len(y_train)
n_classes = len(class_counts)
class_weights_dict = {cls: total / (n_classes * count) for cls, count in class_counts.items()}

print("Poids des classes calculés:")
for cls, weight in class_weights_dict.items():
    print(f"  Classe {cls} ({reverse_mapping[cls]}): {weight:.4f}")

# Créer sample_weight pour chaque échantillon (train, val, test)
sample_weight_train = compute_sample_weight(class_weight='balanced', y=y_train)
sample_weight_val = compute_sample_weight(class_weight='balanced', y=y_val)

print(f"\nSample weights créés:")
print(f"  Train: {sample_weight_train.shape}, min={sample_weight_train.min():.4f}, max={sample_weight_train.max():.4f}")
print(f"  Val: {sample_weight_val.shape}, min={sample_weight_val.min():.4f}, max={sample_weight_val.max():.4f}")

base_params = {
    'objective': 'multi:softprob',
    'num_class': 3,
    'eval_metric': 'mlogloss',
    'tree_method': 'hist',
    'random_state': 42,
    'n_jobs': -1
}

# Distributions pour RandomizedSearchCV
param_distributions = {
    'max_depth': randint(5, 15),
    'learning_rate': uniform(0.01, 0.19),
    'n_estimators': randint(100, 300),
    'min_child_weight': randint(1, 7),
    'subsample': uniform(0.6, 0.4),
    'colsample_bytree': uniform(0.6, 0.4),
    'gamma': uniform(0, 0.3),
    'reg_alpha': uniform(0, 1),
    'reg_lambda': uniform(0.5, 1.5)
}

# TimeSeriesSplit sur TRAIN uniquement
tscv = TimeSeriesSplit(n_splits=5)



xgb_model = xgb.XGBClassifier(**base_params)

random_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_distributions,
    n_iter=50,
    cv=tscv,
    scoring='neg_log_loss',
    n_jobs=-1,
    verbose=1,
    random_state=42
)

print("\nLancement de RandomizedSearchCV avec sample_weight...")
random_search.fit(X_train, y_train, sample_weight=sample_weight_train)

best_params = random_search.best_params_

print("BEST HYPERPARAMÈTRES")

for param, value in sorted(best_params.items()):
    print(f"  {param}: {value}")
print(f"\nMeilleur score CV (neg_log_loss): {-random_search.best_score_:.4f}")

final_model = xgb.XGBClassifier(
    **base_params,
    **best_params,
    early_stopping_rounds=50
)

eval_set = [(X_val, y_val)]

final_model.fit(
    X_train,
    y_train,
    sample_weight=sample_weight_train,
    eval_set=eval_set,
    sample_weight_eval_set=[sample_weight_val],
    verbose=50
)

print(f"\nNombre d'arbres utilisés: {final_model.best_iteration}")
print(f"Meilleur score validation: {final_model.best_score:.4f}")

y_pred = final_model.predict(X_test)
y_pred_proba = final_model.predict_proba(X_test)

# Métriques globales
accuracy = accuracy_score(y_test, y_pred)
precision_macro = precision_score(y_test, y_pred, average='macro')
recall_macro = recall_score(y_test, y_pred, average='macro')
f1_macro = f1_score(y_test, y_pred, average='macro')
f1_weighted = f1_score(y_test, y_pred, average='weighted')

print(f"\n{'='*60}")
print("RÉSULTATS SUR TEST SET")
print("="*60)
print(f"Accuracy:            {accuracy:.4f}")
print(f"Precision (macro):   {precision_macro:.4f}")
print(f"Recall (macro):      {recall_macro:.4f}")
print(f"F1-Score (macro):    {f1_macro:.4f}")
print(f"F1-Score (weighted): {f1_weighted:.4f}")

# ROC-AUC multiclasse (one-vs-rest)
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
roc_auc_ovr = roc_auc_score(y_test_bin, y_pred_proba, multi_class='ovr', average='macro')
print(f"ROC-AUC (OVR macro): {roc_auc_ovr:.4f}")

print(f"\n{'-'*60}")
print("Classification Report:")
print(classification_report(y_test, y_pred,
                          target_names=['Down', 'Hold', 'Up'],
                          digits=4))

print(f"\n{'='*60}")
print("GÉNÉRATION OF VISUALISATIONS")
print("="*60)

fig = plt.figure(figsize=(18, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# 6.1 Matrice de confusion détaillée
ax1 = fig.add_subplot(gs[0:2, 0:2])
cm = confusion_matrix(y_test, y_pred)
cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

annot = np.empty_like(cm).astype(str)
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        annot[i, j] = f'{cm[i, j]}\n({cm_percent[i, j]:.1f}%)'

sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', ax=ax1,
            xticklabels=['Down', 'Hold', 'Up'],
            yticklabels=['Down', 'Hold', 'Up'],
            cbar_kws={'label': 'Count'})
ax1.set_title(' Confusion Matrice (Test Set)', fontsize=14, fontweight='bold')
ax1.set_ylabel('True Classe', fontsize=12)
ax1.set_xlabel('Predicted Classe ', fontsize=12)

# 6.2 Distribution des prédictions
ax2 = fig.add_subplot(gs[0, 2])
pred_counts = pd.Series(y_pred).value_counts().sort_index()
colors = ['red', 'gray', 'green']
ax2.bar(['Down', 'Hold', 'Up'], pred_counts.values, color=colors, alpha=0.7, edgecolor='black')
ax2.set_title('Distribution des Prédictions', fontsize=12, fontweight='bold')
ax2.set_ylabel('Count')
ax2.grid(axis='y', alpha=0.3)
for i, v in enumerate(pred_counts.values):
    ax2.text(i, v + 5, str(v), ha='center', fontweight='bold')

# 6.3 Distribution des vraies classes (test)
ax3 = fig.add_subplot(gs[1, 2])
true_counts = pd.Series(y_test).value_counts().sort_index()
ax3.bar(['Down', 'Hold', 'Up'], true_counts.values, color=colors, alpha=0.7, edgecolor='black')
ax3.set_title('Distribution Vraies Classes', fontsize=12, fontweight='bold')
ax3.set_ylabel('Count')
ax3.grid(axis='y', alpha=0.3)
for i, v in enumerate(true_counts.values):
    ax3.text(i, v + 5, str(v), ha='center', fontweight='bold')

# 6.4 Distribution des probabilités par classe
ax4 = fig.add_subplot(gs[2, 0])
ax4.hist(y_pred_proba[:, 0], bins=30, alpha=0.6, label='Down', color='red', edgecolor='black')
ax4.hist(y_pred_proba[:, 1], bins=30, alpha=0.6, label='Hold', color='gray', edgecolor='black')
ax4.hist(y_pred_proba[:, 2], bins=30, alpha=0.6, label='Up', color='green', edgecolor='black')
ax4.set_xlabel('predicted probability')
ax4.set_ylabel('Fréquency')
ax4.set_title('Distribution of the Probability', fontsize=12, fontweight='bold')
ax4.legend()
ax4.grid(True, alpha=0.3)

# 6.5 Confiance des prédictions (correctes vs incorrectes)
ax5 = fig.add_subplot(gs[2, 1])
max_proba = y_pred_proba.max(axis=1)
correct_pred = (y_pred == y_test)
ax5.hist(max_proba[correct_pred], bins=30, alpha=0.6, label='Correct', color='green', edgecolor='black')
ax5.hist(max_proba[~correct_pred], bins=30, alpha=0.6, label='Incorrect', color='red', edgecolor='black')
ax5.set_xlabel('maximal Probability ')
ax5.set_ylabel('Fréquency')
ax5.set_title('Confidence of the Prédictions', fontsize=12, fontweight='bold')
ax5.legend()
ax5.grid(True, alpha=0.3)
ax5.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='Seuil 0.5')

# 6.6 Métriques par classe (barplot)
ax6 = fig.add_subplot(gs[2, 2])
report_dict = classification_report(y_test, y_pred, output_dict=True,
                                   target_names=['Down', 'Hold', 'Up'])
metrics_data = {
    'Down': [report_dict['Down']['precision'],
             report_dict['Down']['recall'],
             report_dict['Down']['f1-score']],
    'Hold': [report_dict['Hold']['precision'],
             report_dict['Hold']['recall'],
             report_dict['Hold']['f1-score']],
    'Up': [report_dict['Up']['precision'],
           report_dict['Up']['recall'],
           report_dict['Up']['f1-score']]
}
x = np.arange(3)
width = 0.25
ax6.bar(x - width, metrics_data['Down'], width, label='Down', color='red', alpha=0.7, edgecolor='black')
ax6.bar(x, metrics_data['Hold'], width, label='Hold', color='gray', alpha=0.7, edgecolor='black')
ax6.bar(x + width, metrics_data['Up'], width, label='Up', color='green', alpha=0.7, edgecolor='black')
ax6.set_ylabel('Score')
ax6.set_title('Métriques par Classe', fontsize=12, fontweight='bold')
ax6.set_xticks(x)
ax6.set_xticklabels(['Precision', 'Recall', 'F1-Score'])
ax6.legend()
ax6.set_ylim([0, 1])
ax6.grid(axis='y', alpha=0.3)

plt.suptitle('Analyse Complète du Modèle XGBoost Multiclasse', fontsize=16, fontweight='bold', y=0.995)
plt.show()

print("✓ Visualisations générées avec succès!")

booster = final_model.get_booster()
current_dir =Path(__file__).parent
destination_dir = current_dir.parent / "models" / "final_xgb_3cat.json"
booster.save_model(destination_dir)