# -*- coding: utf-8 -*-
"""fetch_data_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rgc3ltcA-5dySOW2eyarpiCYg83J5hZB

In this file, I’m collecting various data from a company and compiling it into a CSV file containing all the raw information. Most of the data consists of technical indicators and basic company metrics that could be used to predict short-term price movements. The output of this process is a raw, unnormalized CSV file. Some of the indicators are redundant or highly correlated, which is why we’ll need another script to process and refine the data later.
"""

import pandas as pd
import requests
import json
from pathlib import Path
from dotenv import load_dotenv
import os


load_dotenv()
# Api_key = os.getenv("API_KEY1")
Api_key = os.getenv("API_KEY2")
# Api_key = os.getenv("API_KEY3")
symbol = "Coca"
interval = "daily"
time_period = "5"
series_type = "close"
maturity="15year"
outputsize = "full"
current_dir = Path(__file__).parent

"""Here are the function used to retreive the data from the ALphavantage api refer to their documentation for further information consult : https://www.alphavantage.co/documentation/"""

#  --- OPEN CLOSE LOW HIGH VOLUME ---
def retriveOCLHV( symbol : str,outputsize:str, Api_key : str  ) ->dict:
  url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize={outputsize}&interval=daily&apikey={Api_key}"
  response = requests.get(url)
  data = response.text
  parsedata = json.loads(data)
  return parsedata
def retriveShares(symbol :str, Api_key : str  ) ->dict:
  url = f"https://www.alphavantage.co/query?function=SHARES_OUTSTANDING&symbol={symbol}&interval=daily&apikey={Api_key}"
  response = requests.get(url)
  data = response.text
  parsedata = json.loads(data)
  return parsedata
#  --- WMA ---
def retriveWMA( symbol : str, Api_key : str  ,interval:str, time_period :str,outputsize:str) ->dict:
  url = f"  https://www.alphavantage.co/query?function=WMA&symbol={symbol}&interval={interval}&time_period={time_period}&series_type=close&outputsize={outputsize}&apikey={Api_key}"
  response = requests.get(url)
  data = response.text
  parsedata = json.loads(data)
  return parsedata
#  --- Earnings Estimates ---
# return earning per share
def retrieveEarningsEstimates(symbol: str, api_key: str) -> dict:
    """Récupère les estimations de bénéfices."""
    url = f"https://www.alphavantage.co/query?function=EARNINGS&symbol={symbol}&interval=daily&outputsize=full&apikey={api_key}"

    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


#  --- RSI ---
def retrieveRSI(symbol: str, api_key: str, interval : str, outputsize : str,series_type:str, time_period :str) -> dict:
    """Récupère le RSI d'une action."""
    url = f"https://www.alphavantage.co/query?function=RSI&symbol={symbol}&interval={interval}&time_period={time_period}&outputsize={outputsize}&series_type={series_type}&datatype=json&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


#  --- Bollinger Bands ---
def retrieveBBANDS(symbol: str, api_key: str, outputsize : str, interval : str,series_type:str, time_period:str,) -> dict:
    """Récupère les bandes de Bollinger."""
    url = f"https://www.alphavantage.co/query?function=BBANDS&symbol={symbol}&interval={interval}&time_period={time_period}&series_type={series_type}&outputsize={outputsize}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- Stochastic Oscillator ---
def retrieveSTOCH(symbol: str, api_key: str, outputsize : str, interval : str) -> dict:
    """Récupère le Stochastic Oscillator."""
    url = f"https://www.alphavantage.co/query?function=STOCH&symbol={symbol}&interval={interval}&outputsize={outputsize}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata

# --- ADX (Average Directional Movement Index) ---
def retrieveADX(symbol: str, api_key: str, interval : str, time_period: str) -> dict:
    """Récupère l'indicateur ADX."""
    url = f"https://www.alphavantage.co/query?function=ADX&symbol={symbol}&interval={interval}&time_period={time_period}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- On-Balance Value (HT_TRENDLINE) ---
def retrieveOBV(symbol: str, api_key: str, interval : str, time_period: str) -> dict:
    """Récupère la tendance de volume (HT_TRENDLINE)."""
    url = f"https://www.alphavantage.co/query?function=OBV&symbol={symbol}&interval={interval}&time_period={time_period}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- CCI (Commodity Channel Index) ---
def retrieveCCI(symbol: str, api_key: str, interval : str, time_period :str) -> dict:
    """Récupère le CCI."""
    url = f"https://www.alphavantage.co/query?function=CCI&symbol={symbol}&interval={interval}&time_period={time_period}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- GDP per capita ---
def retrieveGDPPerCapita(api_key: str) -> dict:
    """Récupère le PIB par habitant."""
    url = f"https://www.alphavantage.co/query?function=REAL_GDP_PER_CAPITA&interval=daily&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- Treasury Yield ---
def retrieveTreasuryYield(api_key: str, interval: str, maturity :str) -> dict:
    """Récupère les taux du Trésor américain."""
    url = f"https://www.alphavantage.co/query?function=TREASURY_YIELD&interval={interval}&maturity={maturity}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- Interest Rates (Federal Funds Rate) ---
def retrieveInterestRates(api_key: str, interval: str) -> dict:
    """Récupère les taux directeurs de la FED."""
    url = f"https://www.alphavantage.co/query?function=FEDERAL_FUNDS_RATE&interval={interval}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- Unemployment Rate ---
def retrieveUnemployment(api_key: str, interval: str) -> dict:
    """Récupère le taux de chômage."""
    url = f"https://www.alphavantage.co/query?function=UNEMPLOYMENT&interval={interval}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- MACD Extended ---
def retrieveMACDEXT(symbol: str, api_key: str, interval : str, series_type="open") -> dict:
    """Récupère le MACD étendu."""
    url = f"https://www.alphavantage.co/query?function=MACDEXT&symbol={symbol}&interval={interval}&series_type={series_type}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata


# --- APO (Absolute Price Oscillator) ---
def retrieveAPO(symbol: str, api_key: str, interval : str, series_type="close", fastperiod="10", matype="2") -> dict:
    """Récupère l'oscillateur de moyenne mobile."""
    url = f"https://www.alphavantage.co/query?function=APO&symbol={symbol}&interval={interval}&series_type={series_type}&fastperiod={fastperiod}&matype={matype}&apikey={api_key}"
    response = requests.get(url)
    data = response.text
    parsedata = json.loads(data)
    return parsedata

data0 =retriveOCLHV(symbol,outputsize , Api_key)

time_series = data0["Time Series (Daily)"]
df_OCLHV = pd.DataFrame.from_dict(time_series, orient="index")
df_OCLHV.columns = ["open", "high", "low", "close", "volume"]

df_OCLHV.index = pd.to_datetime(df_OCLHV.index)
df_OCLHV.index.name = 'date'

#convert values from string to float :
df_OCLHV["open"] = pd.to_numeric(df_OCLHV["open"], errors="coerce")
df_OCLHV["close"] = pd.to_numeric(df_OCLHV["close"], errors="coerce")
df_OCLHV["high"] = pd.to_numeric(df_OCLHV["high"], errors="coerce")
df_OCLHV["low"] = pd.to_numeric(df_OCLHV["low"], errors="coerce")
df_OCLHV["volume"] = pd.to_numeric(df_OCLHV["volume"], errors="coerce")

df_OCLHV = df_OCLHV.sort_index()

df_OCLHV['open'] = df_OCLHV['open'].interpolate(method='time')
df_OCLHV['close'] = df_OCLHV['close'].interpolate(method='time')
df_OCLHV['high'] = df_OCLHV['high'].interpolate(method='time')
df_OCLHV['low'] = df_OCLHV['low'].interpolate(method='time')
df_OCLHV['volume'] = df_OCLHV['volume'].interpolate(method='time')


# if their is still NAN at the extremities we fill them
df_OCLHV['open'] = df_OCLHV['open'].fillna(method='bfill').fillna(method='ffill')

data1 =retriveShares(symbol , Api_key)

records = []
for item in data1['data']:
    records.append({
        'date': item['date'],
        'shares_outstanding_basic': item['shares_outstanding_basic']
    })
df_Shares = pd.DataFrame(records)

df_Shares['date'] = pd.to_datetime(df_Shares['date'])
df_Shares["shares_outstanding_basic"] = pd.to_numeric(df_Shares["shares_outstanding_basic"], errors="coerce")
# define date as index
df_Shares.set_index('date', inplace=True)

# sort by date
df_Shares.sort_index(inplace=True)
df_Shares['shares_outstanding_basic'] = df_Shares['shares_outstanding_basic'].interpolate(method='time')

# if their is still NAN at the extremities we fill them
df_Shares['shares_outstanding_basic'] = df_Shares['shares_outstanding_basic'].fillna(method='bfill').fillna(method='ffill')
df_Shares.tail()

data3 = retriveWMA(symbol,Api_key,interval, time_period, outputsize)

records = []
wma_data = data3['Technical Analysis: WMA']
for date, values in wma_data.items():
    records.append({
        'date': date,
        'WMA': values['WMA']
    })
df_WMA = pd.DataFrame(records)
df_WMA['date'] = pd.to_datetime(df_WMA['date'])
df_WMA['WMA']= pd.to_numeric(df_WMA['WMA'], errors='coerce')
# defien date as index
df_WMA.set_index('date', inplace=True)

# sort by date
df_WMA.sort_index(inplace=True)
df_WMA['WMA'] = df_WMA['WMA'].interpolate(method='time')

# # if their is still NAN at the extremities we fill them
df_WMA['WMA'] = df_WMA['WMA'].fillna(method='bfill').fillna(method='ffill')

data4= retrieveRSI(symbol , Api_key, interval, outputsize,series_type,time_period)

records = []
rsi_data = data4['Technical Analysis: RSI']
for date, values in rsi_data.items():
    records.append({
        'date': date,
        'RSI': values['RSI']
    })
df_RSI = pd.DataFrame(records)
df_RSI['date'] = pd.to_datetime(df_RSI['date'])
df_RSI['RSI'] = pd.to_numeric(df_RSI['RSI'])


df_RSI.set_index('date', inplace=True)


df_RSI.sort_index(inplace=True)
df_RSI['RSI'] = df_RSI['RSI'].interpolate(method='time')


df_RSI['RSI'] = df_RSI['RSI'].fillna(method='bfill').fillna(method='ffill')
df_RSI.tail()

data5 = retrieveBBANDS(symbol, Api_key,outputsize,interval,series_type,time_period)

records = []

bbands_data = data5["Technical Analysis: BBANDS"]

for date, values in bbands_data.items():
    records.append({
        'date': date,
        'Real Upper Band': values["Real Upper Band"],
        'Real Middle Band': values["Real Middle Band"],
        'Real Lower Band': values["Real Lower Band"]
    })

df_BBANDS = pd.DataFrame(records)

df_BBANDS['date'] = pd.to_datetime(df_BBANDS['date'])
df_BBANDS["Real Upper Band"] = pd.to_numeric(df_BBANDS["Real Upper Band"], errors="coerce")
df_BBANDS["Real Middle Band"] = pd.to_numeric(df_BBANDS["Real Middle Band"], errors="coerce")
df_BBANDS["Real Lower Band"] = pd.to_numeric(df_BBANDS["Real Lower Band"], errors="coerce")


df_BBANDS.set_index('date', inplace=True)

df_BBANDS.sort_index(inplace=True)


df_BBANDS['Real Upper Band'] = df_BBANDS['Real Upper Band'].interpolate(method='time')
df_BBANDS['Real Middle Band'] = df_BBANDS['Real Middle Band'].interpolate(method='time')
df_BBANDS['Real Lower Band'] = df_BBANDS['Real Lower Band'].interpolate(method='time')

df_BBANDS['Real Upper Band'] = df_BBANDS['Real Upper Band'].fillna(method='bfill').fillna(method='ffill')
df_BBANDS['Real Middle Band'] = df_BBANDS['Real Middle Band'].fillna(method='bfill').fillna(method='ffill')
df_BBANDS['Real Lower Band'] = df_BBANDS['Real Lower Band'].fillna(method='bfill').fillna(method='ffill')

data6 = retrieveSTOCH(symbol,Api_key,outputsize,interval)

records = []

STOCH_data = data6["Technical Analysis: STOCH"]

for date, values in STOCH_data.items():
    records.append({
        'date': date,
        'SlowK': values["SlowK"],
        'SlowD': values["SlowD"]
    })

df_STOCH = pd.DataFrame(records)

df_STOCH["SlowK"] = pd.to_numeric(df_STOCH["SlowK"], errors="coerce")
df_STOCH["SlowD"] = pd.to_numeric(df_STOCH["SlowD"], errors="coerce")

df_STOCH['date'] = pd.to_datetime(df_STOCH['date'])

df_STOCH.set_index('date', inplace=True)

df_STOCH.sort_index(inplace=True)

df_STOCH['SlowD'] = df_STOCH['SlowD'].interpolate(method='time')
df_STOCH['SlowK'] = df_STOCH['SlowK'].interpolate(method='time')


# if their is still NAN at the extremities we fill them
df_STOCH['SlowD'] = df_STOCH['SlowD'].fillna(method='bfill').fillna(method='ffill')
df_STOCH['SlowK'] = df_STOCH['SlowK'].fillna(method='bfill').fillna(method='ffill')

dataadx = retrieveADX(symbol,Api_key,interval,time_period)

records = []
ADX_data = dataadx['Technical Analysis: ADX']
for date, values in ADX_data.items():
    records.append({
        'date': date,
        'ADX': values['ADX']
    })
df_ADX = pd.DataFrame(records)
df_ADX['date'] = pd.to_datetime(df_ADX['date'])
df_ADX["ADX"] = pd.to_numeric(df_ADX["ADX"], errors="coerce")

df_ADX.set_index('date', inplace=True)


df_ADX.sort_index(inplace=True)

df_ADX['ADX'] = df_ADX['ADX'].interpolate(method='time')

df_ADX['ADX'] = df_ADX['ADX'].fillna(method='bfill').fillna(method='ffill')

df_ADX.tail()

data7= retrieveOBV(symbol, Api_key, interval, time_period)

records = []
OBV_data = data7['Technical Analysis: OBV']
for date, values in OBV_data.items():
    records.append({
        'date': date,
        'OBV': values['OBV']
    })
df_OBV = pd.DataFrame(records)
df_OBV['date'] = pd.to_datetime(df_OBV['date'])
df_OBV["OBV"] = pd.to_numeric(df_OBV["OBV"], errors="coerce")

df_OBV.set_index('date', inplace=True)


df_OBV.sort_index(inplace=True)

df_OBV['OBV'] = df_OBV['OBV'].interpolate(method='time')


df_OBV['OBV'] = df_OBV['OBV'].fillna(method='bfill').fillna(method='ffill')
df_OBV.tail()

data8 = retrieveCCI(symbol, Api_key,interval,time_period)

records = []
CCI_data = data8['Technical Analysis: CCI']
for date, values in CCI_data.items():
    records.append({
        'date': date,
        'CCI': values['CCI']
    })
df_CCI = pd.DataFrame(records)
df_CCI['date'] = pd.to_datetime(df_CCI['date'])
df_CCI["CCI"] = pd.to_numeric(df_CCI["CCI"], errors="coerce")


df_CCI.set_index('date', inplace=True)


df_CCI.sort_index(inplace=True)

# interpolate missing values
df_CCI['CCI'] = df_CCI['CCI'].interpolate(method='time')


df_CCI['CCI'] = df_CCI['CCI'].fillna(method='bfill').fillna(method='ffill')

data9 =retrieveMACDEXT(symbol, Api_key, interval,series_type)

records = []

MACDEXT_data = data9["Technical Analysis: MACDEXT"]

for date, values in MACDEXT_data.items():
    records.append({
        'date': date,
        'MACD': values["MACD"],
        'MACD_Signal': values["MACD_Signal"],
        "MACD_Hist":  values["MACD_Hist"]
    })

df_MACDEXT = pd.DataFrame(records)

df_MACDEXT["MACD_Hist"] = pd.to_numeric(df_MACDEXT["MACD_Hist"], errors="coerce")
df_MACDEXT["MACD"] = pd.to_numeric(df_MACDEXT["MACD"], errors="coerce")
df_MACDEXT["MACD_Signal"] = pd.to_numeric(df_MACDEXT["MACD_Signal"], errors="coerce")

df_MACDEXT['date'] = pd.to_datetime(df_MACDEXT['date'])

df_MACDEXT.set_index('date', inplace=True)

df_MACDEXT.sort_index(inplace=True)


# Interpoler missing values
df_MACDEXT['MACD_Signal'] = df_MACDEXT['MACD_Signal'].interpolate(method='time')
df_MACDEXT['MACD'] = df_MACDEXT['MACD'].interpolate(method='time')
df_MACDEXT['MACD_Hist'] = df_MACDEXT['MACD_Hist'].interpolate(method='time')

df_MACDEXT['MACD_Signal'] = df_MACDEXT['MACD_Signal'].fillna(method='bfill').fillna(method='ffill')
df_MACDEXT['MACD'] = df_MACDEXT['MACD'].fillna(method='bfill').fillna(method='ffill')
df_MACDEXT['MACD_Hist'] = df_MACDEXT['MACD_Hist'].fillna(method='bfill').fillna(method='ffill')

# dataeps = retrieveEarningsEstimates(symbol, Api_key)
# earning per share would be useless at low term
#continuer ici

data10 = retrieveAPO(symbol, Api_key,interval,series_type,)



records = []
APO_data = data10['Technical Analysis: APO']
for date, values in APO_data.items():
    records.append({
        'date': date,
        'APO': values['APO']
    })
df_APO = pd.DataFrame(records)
df_APO['date'] = pd.to_datetime(df_APO['date'])

df_APO.set_index('date', inplace=True)


df_APO.sort_index(inplace=True)



df_APO['APO'] = df_APO['APO'].interpolate(method='time')


df_APO['APO'] = df_APO['APO'].fillna(method='bfill').fillna(method='ffill')

df_APO.tail()

"""fetching and preporcessing macroeconomics data for etf like s&p500

"""

# data11= retrieveTreasuryYield(Api_key, interval, maturity)

# records = []
# for item in data11['data']:
#     records.append({
#         'date': item['date'],
#         'value': item['value']
#     })
# df_yield = pd.DataFrame(records)
# df_yield['date'] = pd.to_datetime(df_yield['date'])
# df_yield['value'] = pd.to_numeric(df_yield['value'], errors='coerce')

# df_yield.set_index('date', inplace=True)


# df_yield.sort_index(inplace=True)


# df_yield['value'] = df_yield['value'].interpolate(method='time')


# df_yield['value'] = df_yield['value'].fillna(method='bfill').fillna(method='ffill')

# df_yield.tail()



# data12 = retrieveGDPPerCapita(Api_key)

# records = []
# for item in data12['data']:
#     records.append({
#         'date': item['date'],
#         'value': item['value']
#     })
# df_GDP = pd.DataFrame(records)
# df_GDP['date'] = pd.to_datetime(df_GDP['date'])
# df_GDP['value'] = pd.to_numeric(df_GDP['value'], errors='coerce')

# df_GDP.set_index('date', inplace=True)


# df_GDP.sort_index(inplace=True)

# df_GDP['value'] = df_GDP['value'].interpolate(method='time')


# df_GDP['value'] = df_GDP['value'].fillna(method='bfill').fillna(method='ffill')

# df_GDP.tail()

# data13= retrieveUnemployment(Api_key, interval)

# records = []
# for item in data13['data']:
#     records.append({
#         'date': item['date'],
#         'value': item['value']
#     })
# df_UNEMPLOY = pd.DataFrame(records)
# df_UNEMPLOY['date'] = pd.to_datetime(df_UNEMPLOY['date'])
# df_UNEMPLOY['value'] = pd.to_numeric(df_UNEMPLOY['value'], errors='coerce')

# df_UNEMPLOY.set_index('date', inplace=True)


# df_UNEMPLOY.sort_index(inplace=True)


# df_UNEMPLOY['value'] = df_UNEMPLOY['value'].interpolate(method='time')


# df_UNEMPLOY['value'] = df_UNEMPLOY['value'].fillna(method='bfill').fillna(method='ffill')

# data14= retrieveInterestRates(Api_key, interval)

# records = []
# for item in data14['data']:
#     records.append({
#         'date': item['date'],
#         'value': item['value']
#     })
# df_INTEREST = pd.DataFrame(records)
# df_INTEREST['date'] = pd.to_datetime(df_INTEREST['date'])
# df_INTEREST['value'] = pd.to_numeric(df_INTEREST['value'], errors='coerce')

# df_INTEREST.set_index('date', inplace=True)



# df_INTEREST.sort_index(inplace=True)


# df_INTEREST['value'] = df_INTEREST['value'].interpolate(method='time')


# df_INTEREST['value'] = df_INTEREST['value'].fillna(method='bfill').fillna(method='ffill')

def  join_DataStock( df_ADX :pd.DataFrame, df_APO :pd.DataFrame, df_BBANDS :pd.DataFrame, df_CCI :pd.DataFrame,df_MACDEXT :pd.DataFrame,
                    df_OBV :pd.DataFrame, df_OCLHV :pd.DataFrame, df_RSI :pd.DataFrame, df_STOCH :pd.DataFrame, df_Shares :pd.DataFrame
                     ,df_WMA:pd.DataFrame) -> pd.DataFrame:
    df_combined = pd.concat([
        df_OCLHV,
        df_ADX,
        df_APO,
        df_BBANDS,
        df_CCI,
        df_MACDEXT,
        df_OBV,
        df_RSI,
        df_STOCH,
        df_Shares,
        df_WMA
    ], axis=1, join='outer')


    df_combined.sort_index(inplace=True)


    df_combined = df_combined.interpolate(method='time')

    df_combined = df_combined.fillna(method='bfill').fillna(method='ffill')

    return df_combined

df_complete= join_DataStock(df_ADX, df_APO, df_BBANDS, df_CCI, df_MACDEXT, df_OBV, df_OCLHV, df_RSI, df_STOCH, df_Shares, df_WMA)


csv_folder = current_dir.parent.parent / "csv" / "Coca"
csv_folder.mkdir(parents=True, exist_ok=True)
csv_path = csv_folder / "completerawdata.csv"

df_complete.to_csv(csv_path,  index=True, index_label="date")

"""file saved on google drive"""